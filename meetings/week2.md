# Week 2 Markov Decision Process - A problem statement of Reinforcement Learning

## Overview of RL

RL has many applications in different fields ranging from Optimal Control, Reward System, Operations Research (Economics), etc. It is indeed a huge distinct branch
in Machine Learning beside Supervised and Unsupervised Learning. There are important aspects in the formulation of RL:

- No supervisor, only reward signal serves as heuristic guidance.
- RL is stochastic, so feedback is not instantaneous.
- The variables are sequential time-dependent.
- Action affects subsequent observable data.

Using RL, we try to build an agent that acts ![alt text](https://latex.codecogs.com/gif.latex?A_t) based on the feedback reward signal ![alt text](https://latex.codecogs.com/gif.latex?R_t) and observation 
![alt text](https://latex.codecogs.com/gif.latex?O_t):



## Markov Process


## Markov Decision Process (MDP)

### MDP Formulation

### Optimal Policy for MDP
